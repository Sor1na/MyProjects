{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f87ec0f-e138-4c8f-8a10-7e59a02cb7c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b9359-2d51-4d44-ad26-3e4dafb5d94a",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822cbe81-f21c-40a8-a2e7-b02dd1bcc4ae",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классификации комментариев на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Модель со значением метрики качества *F1* не меньше 0.75 будет достаточно эффективной. \n",
    "\n",
    "**План выполнения проекта**\n",
    "\n",
    "1. Загрузка и подготовка данных.\n",
    "2. Обучение разных моделей. \n",
    "3. Итоговые выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99947bde-794f-405b-a050-ab7a497c0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34a09c-4ddc-4090-9365-098274dc64e9",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f051591-72ff-486e-bee4-e4ea3c475412",
   "metadata": {},
   "source": [
    "Взглянем на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6030c1e6-d346-4118-8d4e-5989b711b036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"toxic_comments.csv\", index_col=0)\n",
    "display(data.head(5))\n",
    "display(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a5c72e-4b94-48f6-b2ba-756288c0098b",
   "metadata": {},
   "source": [
    "Данные импортировались правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10046a29-c831-4028-b791-376060e24522",
   "metadata": {},
   "source": [
    "Возьмем тренировочную выборку из 1000 элементов, для ускорения обучения, а валидационную и тестовую из 200 элементов. Чтобы модель научилась определять токсичные комментрарии, возьмем тренировочную выборку с равным соотношением токсичных и нетоксичных комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d090b88-0711-4ea1-95fc-ed9261575d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение датасета на обучающую и тестовую выборки с ограничением размера\n",
    "train_data, test_data = train_test_split(data, test_size=200/len(data), random_state=1)\n",
    "\n",
    "test_data = test_data.sample(n=200, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Балансировка классов в обучающей выборке\n",
    "data_0 = train_data[train_data['toxic'] == 0]\n",
    "data_1 = train_data[train_data['toxic'] == 1]\n",
    "\n",
    "half_n = min(len(data_0), len(data_1), 2000)\n",
    "sampled_data_0 = data_0.sample(n=half_n, random_state=1)\n",
    "sampled_data_1 = data_1.sample(n=half_n, random_state=1)\n",
    "\n",
    "balanced_train_data = pd.concat([sampled_data_0, sampled_data_1]).reset_index(drop=True)\n",
    "balanced_train_data = balanced_train_data.sample(n=4000, random_state=1).reset_index(drop=True)\n",
    "\n",
    "#balanced_train_data = train_data.sample(2000, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfefac-4053-4ca2-9189-0c070a9b3c78",
   "metadata": {},
   "source": [
    "Токенизируем текста и создадим маску(сделаем это в функции):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e889a587-c2b2-49ae-9e5c-81161e3efa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация и создание эмбеддингов для обучающей выборки\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Функция для токенизации\n",
    "def tokenize_data(data):\n",
    "    tokenized = data['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    \n",
    "    padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "    \n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "    return padded, attention_mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848a4b80-52a8-4104-90f7-5c89bd3c431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "\"\"\"\n",
    "# Токенизация обучающих данных\n",
    "padded_train, attention_mask_train = tokenize_data(balanced_train_data)\n",
    "\n",
    "# Токенизация тестовых данных\n",
    "padded_test, attention_mask_test = tokenize_data(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b70f3-8379-4f8d-aa46-0e3eb15ae13b",
   "metadata": {},
   "source": [
    "Загрузим файлы конфигурации и обученной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8c5ea8-df18-49d7-aac0-133fb340f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9161b2-2534-4654-a090-6638586da8e0",
   "metadata": {},
   "source": [
    "Переведем текст в эмбединги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a9b667d-7ff0-404d-a94c-60c01d451ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20a020c02de46838f4967b215f42704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fbe16d70644845b19ad257ad737446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Обрезка padded и attention_mask до максимальной длины в 512 токенов\n",
    "max_length = 512\n",
    "padded_train = padded_train[:, :max_length]\n",
    "attention_mask_train = attention_mask_train[:, :max_length]\n",
    "\n",
    "padded_test = padded_test[:, :max_length]\n",
    "attention_mask_test = attention_mask_test[:, :max_length]\n",
    "\n",
    "#функция создания эмбеддингов\n",
    "def create_embeddings(padded, attention_mask):\n",
    "    embeddings = []\n",
    "    batch_size = 100\n",
    "    for i in tqdm(range(0, len(padded), batch_size)):\n",
    "        batch = torch.tensor(padded[i:i+batch_size], dtype=torch.long)\n",
    "        attention_mask_batch = torch.tensor(attention_mask[i:i+batch_size], dtype=torch.long)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Создание эмбеддингов для обучающих данных\n",
    "train_embeddings = create_embeddings(padded_train, attention_mask_train)\n",
    "\n",
    "# Создание эмбеддингов для тестовых данных\n",
    "test_embeddings = create_embeddings(padded_test, attention_mask_test)\n",
    "\n",
    "# Конвертация списка вложений в numpy массив для дальнейшего использования\n",
    "#embeddings = np.vstack(embeddings)  # Используйте vstack для объединения списка массивов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02cf81-cc81-4468-afde-fbb5ecd3252b",
   "metadata": {},
   "source": [
    "Создадим датафреймы для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a07b6dd-ca22-4aac-add8-0631e05327ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame(embeddings, data):\n",
    "    features = np.concatenate(embeddings)\n",
    "    data_new = pd.DataFrame(features)\n",
    "    data_new['toxic'] = data['toxic']\n",
    "    return data_new\n",
    "\n",
    "train = create_data_frame(train_embeddings, balanced_train_data)\n",
    "test = create_data_frame(test_embeddings, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0fd9b-41b1-45f5-b3d3-f99104e86e7c",
   "metadata": {},
   "source": [
    "Выделим тренировочную, тестовую и валидационную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a71cac7-6eb8-46d5-b2e5-ba8e22236149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 769), (200, 769))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac3d133-18d2-4142-8aa1-bf93dd7cd200",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['toxic'], axis=1)\n",
    "y_train = train['toxic']\n",
    "\n",
    "X_test_full = test.drop(['toxic'], axis=1)\n",
    "y_test_full = test['toxic']\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_full, y_test_full, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d3502c-43a1-428c-8134-823abca6c023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    0\n",
       "101    0\n",
       "102    0\n",
       "103    1\n",
       "104    0\n",
       "      ..\n",
       "195    1\n",
       "196    0\n",
       "197    0\n",
       "198    0\n",
       "199    0\n",
       "Name: toxic, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5571bf-e5c0-4fa0-bcc7-c94c114293a4",
   "metadata": {},
   "source": [
    "Теперь мы подготовили данные к обучению. Обучим пару моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c05a4-2c97-42bb-aa98-e5ce3e10ad3a",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e32f7-7bc1-4e54-ba80-cc6cc529715f",
   "metadata": {},
   "source": [
    "Создадим две модели МО:\n",
    "- линейную регрессию\n",
    "- дерево решений\n",
    "  \n",
    "Выберем лучшую модель и проверим ее на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f41f7-ee59-4bdd-afc7-5cefd2aa586b",
   "metadata": {},
   "source": [
    "Переберем значения гиперпараметров для линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5518e9ce-2cd4-457b-b1ce-1b56798cf16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры:\n",
      "C: 0.1\n",
      "penalty: l2\n",
      "solver: lbfgs\n",
      "Лучшая F1-мера валидационной выборки: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Диапазоны гиперпараметров\n",
    "C_range = [0.01, 0.1, 0.5, 1, 10, 100]  # Примерные значения для обратной силы регуляризации\n",
    "penalty_range = ['l1', 'l2', 'elasticnet', 'none']  # Виды регуляризации\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = {'C': None, 'penalty': None, 'solver': None}\n",
    "\n",
    "# Перебор гиперпараметров\n",
    "for C in C_range:\n",
    "    for penalty in penalty_range:\n",
    "        # В зависимости от penalty выбираем решатель\n",
    "        if penalty == 'elasticnet':\n",
    "            solver = 'saga'\n",
    "            l1_ratio = 0.5  \n",
    "        elif penalty == 'l1':\n",
    "            solver = 'liblinear'\n",
    "        else:\n",
    "            solver = 'lbfgs'\n",
    "\n",
    "        model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=2000)\n",
    "        \n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            preds_val = model.predict(X_val)\n",
    "            current_f1 = f1_score(y_val, preds_val, average='binary')\n",
    "\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_params['C'] = C\n",
    "                best_params['penalty'] = penalty\n",
    "                best_params['solver'] = solver\n",
    "                \n",
    "\n",
    "        except ValueError:  # В случае, если комбинация параметров не поддерживается\n",
    "            continue\n",
    "\n",
    "best_linear_model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], solver=best_params['solver'], max_iter=1000)\n",
    "best_linear_model.fit(X_train, y_train)\n",
    "print(\"Лучшие параметры:\")\n",
    "print(f\"C: {best_params['C']}\")\n",
    "print(f\"penalty: {best_params['penalty']}\")\n",
    "print(f\"solver: {best_params['solver']}\")\n",
    "print(f\"Лучшая F1-мера валидационной выборки: {best_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565fb06-5a44-4f9e-979d-18dd442275a2",
   "metadata": {},
   "source": [
    "Результат неплохой. Попробуем деревья решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1ebfc8-df21-49b9-a487-8469c4098260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Decision Tree): 0.6329757199322417\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=2)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "y_pred_dt = dt.predict(X_val)\n",
    "\n",
    "# Расчет F1-меры\n",
    "f1_dt = f1_score(y_val, y_pred_dt, average='macro')\n",
    "print(f\"F1 Score (Decision Tree): {f1_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cdbe8-ac0a-4b6e-b979-a56a9265cfb8",
   "metadata": {},
   "source": [
    "Деревья решений с задачей справились хуже. Вероятно, это из-за того, что они хуже описывают взаимосвязь данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0586673c-968a-42f3-adaf-b6c66319f42e",
   "metadata": {},
   "source": [
    "Проверим модель линейной регрессии на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e40af782-8867-4465-a8c1-e3711b642535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score test: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "pred_test = best_linear_model.predict(X_test)\n",
    "\n",
    "f1_test = f1_score(y_test, pred_test, average='binary')\n",
    "print(f\"F1 Score test: {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985c032-93e8-49ab-9c29-70c1a8a57312",
   "metadata": {},
   "source": [
    "Результат хороший ~77 на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71261903-b489-4977-ab1e-c6441b5a2df8",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b02bd9-eea0-45f8-83cf-13cac74b0214",
   "metadata": {},
   "source": [
    "**Этапы работы**: Проект для \"Викишопа\" включал несколько ключевых этапов. Сначала был выполнен импорт и предварительная обработка данных из файла toxic_comments.csv, при этом особое внимание уделялось балансу между токсичными и нетоксичными комментариями. Затем последовала токенизация текста с помощью BertTokenizer от DeepPavlov и преобразование в эмбеддинги с использованием модели BERT. Данные были разделены на тренировочные, тестовые и валидационные выборки, после чего происходило обучение моделей: линейной регрессии и дерева решений.\n",
    "\n",
    "**Результаты и выводы**: В результате линейная регрессия показала лучшие результаты по сравнению с деревом решений, достигнув F1-меры 0.75 на валидационной выборке и 0.74 на тестовой. Это свидетельствует о высокой эффективности выбранной модели для классификации комментариев на токсичные и нетоксичные. Таким образом, задача по созданию инструмента для отсеивания токсичных комментариев в \"Викишопе\" была успешно выполнена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc7416-7ec9-48d3-a69c-53c5cf7a2acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7baed-f079-4a67-ad74-a9bcf24e26a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0228892-0bb0-4901-84b0-4ea1dda6f24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3763,
    "start_time": "2024-03-29T22:39:30.532Z"
   },
   {
    "duration": 245,
    "start_time": "2024-03-29T22:39:34.347Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.594Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.648Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.648Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.649Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.650Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.651Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.652Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.653Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.655Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.655Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.656Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-29T22:39:34.657Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
